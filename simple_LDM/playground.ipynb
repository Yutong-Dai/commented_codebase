{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n",
      "torch.Size([1, 5, 5])\n",
      "tensor([[[0., -inf, -inf, -inf, -inf],\n",
      "         [0., 0., -inf, -inf, -inf],\n",
      "         [0., 0., 0., -inf, -inf],\n",
      "         [0., 0., 0., 0., -inf],\n",
      "         [0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.random.manual_seed(0)\n",
    "QKT = torch.rand(5, 5)\n",
    "v = torch.rand(5, 1)\n",
    "attmap = QKT.unsqueeze(0)\n",
    "print(attmap.shape)\n",
    "mask = torch.empty(attmap.shape[0], attmap.shape[1], attmap.shape[2])\n",
    "mask.fill_(float('-inf'))\n",
    "mask.triu_(1)\n",
    "print(mask.shape)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4963,   -inf,   -inf,   -inf,   -inf],\n",
      "         [0.6341, 0.4901,   -inf,   -inf,   -inf],\n",
      "         [0.3489, 0.4017, 0.0223,   -inf,   -inf],\n",
      "         [0.5185, 0.6977, 0.8000, 0.1610,   -inf],\n",
      "         [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]]])\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5359, 0.4641, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3603, 0.3798, 0.2599, 0.0000, 0.0000],\n",
      "         [0.2369, 0.2834, 0.3140, 0.1657, 0.0000],\n",
      "         [0.2001, 0.2528, 0.1506, 0.2426, 0.1540]]])\n"
     ]
    }
   ],
   "source": [
    "masked_attmap = attmap + mask\n",
    "print(masked_attmap)\n",
    "masked_attmap = torch.softmax(masked_attmap, dim=-1)\n",
    "print(masked_attmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 3, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (1): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [nn.Conv2d(3,3,4)] + [nn.Linear(10,10)]*2 \n",
    "nn.Sequential(*temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 64, 64]) torch.Size([2, 4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "h = torch.rand(2, 8, 64, 64)\n",
    "h_mean_part = h[:, :4]\n",
    "h_log_std_part = h[:, 4:]\n",
    "print(h_mean_part.shape, h_log_std_part.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_encoder import Resnet, Pad, Atten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: torch.Size([2, 3, 512, 512])\n",
      "after input_layer: torch.Size([2, 128, 512, 512])\n",
      "after down_1: torch.Size([2, 128, 256, 256])\n",
      "after down_2: torch.Size([2, 256, 128, 128])\n",
      "after down_3: torch.Size([2, 512, 64, 64])\n",
      "after down_4: torch.Size([2, 512, 64, 64])\n",
      "after mid: torch.Size([2, 512, 64, 64])\n",
      "after out_1: torch.Size([2, 8, 64, 64])\n",
      "after out_1: torch.Size([2, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "in_layer = torch.nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1)\n",
    "down_1 = torch.nn.Sequential(\n",
    "    Resnet(128, 128),\n",
    "    Resnet(128, 128),\n",
    "    torch.nn.Sequential(\n",
    "        Pad(),\n",
    "        torch.nn.Conv2d(128, 128, 3, stride=2, padding=0),\n",
    "    ),\n",
    ")\n",
    "down_2 = torch.nn.Sequential(\n",
    "    Resnet(128, 256),\n",
    "    Resnet(256, 256),\n",
    "    torch.nn.Sequential(\n",
    "        Pad(),\n",
    "        torch.nn.Conv2d(256, 256, 3, stride=2, padding=0),\n",
    "    ),\n",
    ")\n",
    "down_3 = torch.nn.Sequential(\n",
    "    Resnet(256, 512),\n",
    "    Resnet(512, 512),\n",
    "    torch.nn.Sequential(\n",
    "        Pad(),\n",
    "        torch.nn.Conv2d(512, 512, 3, stride=2, padding=0),\n",
    "    ),\n",
    ")\n",
    "\n",
    "down_4 = torch.nn.Sequential(\n",
    "                Resnet(512, 512),\n",
    "                Resnet(512, 512),\n",
    "            )\n",
    "mid = torch.nn.Sequential(\n",
    "    Resnet(512, 512),\n",
    "    Atten(),\n",
    "    Resnet(512, 512),\n",
    ")\n",
    "\n",
    "out_1 = torch.nn.Sequential(\n",
    "    torch.nn.GroupNorm(num_channels=512, num_groups=32, eps=1e-6),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Conv2d(512, 8, 3, padding=1),\n",
    ")\n",
    "\n",
    "out_2 = torch.nn.Conv2d(8, 8, 1)\n",
    "\n",
    "input = torch.rand(2, 3, 512, 512)\n",
    "print('input dim:', input.shape)\n",
    "out = in_layer(input)\n",
    "print('after input_layer:', out.shape)\n",
    "out = down_1(out)\n",
    "print('after down_1:', out.shape)\n",
    "out = down_2(out)\n",
    "print('after down_2:', out.shape)\n",
    "out = down_3(out)\n",
    "print('after down_3:', out.shape)\n",
    "out = down_4(out)\n",
    "print('after down_4:', out.shape)\n",
    "out = mid(out)\n",
    "print('after mid:', out.shape)\n",
    "out = out_1(out)\n",
    "print('after out_1:', out.shape)\n",
    "out = out_2(out)\n",
    "print('after out_1:', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal transformation\n",
    "mean = h[:, :4]\n",
    "# [1, 4, 64, 64]\n",
    "logvar = h[:, 4:]\n",
    "std = logvar.exp()**0.5\n",
    "\n",
    "# [1, 4, 64, 64]\n",
    "h = torch.randn(mean.shape, device=mean.device)\n",
    "h = mean + std * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in\n",
    "in_1 = torch.nn.Conv2d(4, 4, 1)\n",
    "\n",
    "\n",
    "in_2 = torch.nn.Conv2d(4, 512, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# middle\n",
    "middle_1 = torch.nn.Sequential(Resnet(512, 512), Atten(), Resnet(512, 512))\n",
    "\n",
    "# up\n",
    "up_1 = torch.nn.Sequential(\n",
    "    Resnet(512, 512),\n",
    "    Resnet(512, 512),\n",
    "    Resnet(512, 512),\n",
    "    torch.nn.Upsample(scale_factor=2.0, mode='nearest'),\n",
    "    torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    ")\n",
    "up_2 = torch.nn.Sequential(\n",
    "    Resnet(512, 512),\n",
    "    Resnet(512, 512),\n",
    "    Resnet(512, 512),\n",
    "    torch.nn.Upsample(scale_factor=2.0, mode='nearest'),\n",
    "    torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    ")\n",
    "up_3 = torch.nn.Sequential(\n",
    "    Resnet(512, 256),\n",
    "    Resnet(256, 256),\n",
    "    Resnet(256, 256),\n",
    "    torch.nn.Upsample(scale_factor=2.0, mode='nearest'),\n",
    "    torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    ")\n",
    "up_4 = torch.nn.Sequential(\n",
    "    Resnet(256, 128),\n",
    "    Resnet(128, 128),\n",
    "    Resnet(128, 128),\n",
    ")\n",
    "\n",
    "\n",
    "out_1 = torch.nn.Sequential(\n",
    "    torch.nn.GroupNorm(num_channels=128, num_groups=32, eps=1e-6),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Conv2d(128, 3, 3, padding=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: torch.Size([2, 4, 64, 64])\n",
      "after in_1: torch.Size([2, 4, 64, 64])\n",
      "after in_2: torch.Size([2, 512, 64, 64])\n",
      "after middle_1: torch.Size([2, 512, 64, 64])\n",
      "after up_1: torch.Size([2, 512, 128, 128])\n",
      "after up_2: torch.Size([2, 512, 256, 256])\n",
      "after up_3: torch.Size([2, 256, 512, 512])\n",
      "after up_4: torch.Size([2, 128, 512, 512])\n",
      "after out_1: torch.Size([2, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "input = h\n",
    "print('input dim:', input.shape)\n",
    "out = in_1(input)\n",
    "print('after in_1:', out.shape)\n",
    "out = in_2(out)\n",
    "print('after in_2:', out.shape)\n",
    "out = middle_1(out)\n",
    "print('after middle_1:', out.shape)\n",
    "out = up_1(out)\n",
    "print('after up_1:', out.shape)\n",
    "out = up_2(out)\n",
    "print('after up_2:', out.shape)\n",
    "out = up_3(out)\n",
    "print('after up_3:', out.shape)\n",
    "out = up_4(out)\n",
    "print('after up_4:', out.shape)\n",
    "out = out_1(out)\n",
    "print('after out_1:', out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import DownBlock\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input for the next down block: torch.Size([2, 320, 32, 32])\n",
      "input for the corresponding up block: [torch.Size([2, 320, 64, 64]), torch.Size([2, 320, 64, 64]), torch.Size([2, 320, 32, 32])]\n"
     ]
    }
   ],
   "source": [
    "down_0 = DownBlock(dim_in=320, dim_out=320)\n",
    "z_img = torch.rand(2, 320, 64, 64)\n",
    "z_text = torch.rand(2, 77, 768)\n",
    "z_time = torch.rand(2, 1280)\n",
    "out, save = down_0(z_img, z_text, z_time)\n",
    "print('input for the next down block:', out.shape)\n",
    "print('input for the corresponding up block:', [item.shape for item in save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input for the next down block: torch.Size([2, 1280, 8, 8])\n",
      "input for the corresponding up block: [torch.Size([2, 1280, 16, 16]), torch.Size([2, 1280, 16, 16]), torch.Size([2, 1280, 8, 8])]\n"
     ]
    }
   ],
   "source": [
    "down_2 = DownBlock(640, 1280)\n",
    "z_img = torch.rand(2, 640, 16, 16)\n",
    "z_text = torch.rand(2, 77, 768)\n",
    "z_time = torch.rand(2, 1280)\n",
    "out, save = down_2(z_img, z_text, z_time)\n",
    "print('input for the next down block:', out.shape)\n",
    "print('input for the corresponding up block:', [item.shape for item in save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.time = torch.nn.Sequential(\n",
    "            torch.nn.SiLU(),\n",
    "            torch.torch.nn.Linear(1280, dim_out),\n",
    "            torch.nn.Unflatten(dim=1, unflattened_size=(dim_out, 1, 1)),\n",
    "        )\n",
    "\n",
    "        self.s0 = torch.nn.Sequential(\n",
    "            torch.torch.nn.GroupNorm(num_groups=32,\n",
    "                                     num_channels=dim_in,\n",
    "                                     eps=1e-05,\n",
    "                                     affine=True),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.torch.nn.Conv2d(dim_in,\n",
    "                                  dim_out,\n",
    "                                  kernel_size=3,\n",
    "                                  stride=1,\n",
    "                                  padding=1),\n",
    "        )\n",
    "\n",
    "        self.s1 = torch.nn.Sequential(\n",
    "            torch.torch.nn.GroupNorm(num_groups=32,\n",
    "                                     num_channels=dim_out,\n",
    "                                     eps=1e-05,\n",
    "                                     affine=True),\n",
    "            torch.nn.SiLU(),\n",
    "            torch.torch.nn.Conv2d(dim_out,\n",
    "                                  dim_out,\n",
    "                                  kernel_size=3,\n",
    "                                  stride=1,\n",
    "                                  padding=1),\n",
    "        )\n",
    "\n",
    "        self.res = None\n",
    "        if dim_in != dim_out:\n",
    "            self.res = torch.torch.nn.Conv2d(dim_in,\n",
    "                                             dim_out,\n",
    "                                             kernel_size=1,\n",
    "                                             stride=1,\n",
    "                                             padding=0)\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        '''\n",
    "        Why use time embedding?\n",
    "        https://www.reddit.com/r/MachineLearning/comments/101s5kj/r_on_time_embeddings_in_diffusion_models/\n",
    "        '''\n",
    "        # x: [1, 320, 64, 64]\n",
    "        # time: [1, 1280]   time step embedding\n",
    "\n",
    "        res = x\n",
    "\n",
    "        # [1, 1280] -> [1, 640, 1, 1]\n",
    "        time = self.time(time)\n",
    "        print(time.shape)\n",
    "        # [1, 320, 64, 64] -> [1, 640, 32, 32]\n",
    "        print(self.s0(x).shape)\n",
    "        x = self.s0(x) + time\n",
    "\n",
    "        # 维度不变\n",
    "        # [1, 640, 32, 32]\n",
    "        x = self.s1(x)\n",
    "\n",
    "        # [1, 320, 64, 64] -> [1, 640, 32, 32]\n",
    "        if self.res:\n",
    "            res = self.res(res)\n",
    "\n",
    "        # 维度不变\n",
    "        # [1, 640, 32, 32]\n",
    "        x = res + x\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 640, 1, 1])\n",
      "torch.Size([1, 640, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "res = Resnet(320, 640)\n",
    "ans = res(torch.rand(1, 320, 64, 64), torch.rand(1, 1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
