{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n",
      "torch.Size([1, 5, 5])\n",
      "tensor([[[0., -inf, -inf, -inf, -inf],\n",
      "         [0., 0., -inf, -inf, -inf],\n",
      "         [0., 0., 0., -inf, -inf],\n",
      "         [0., 0., 0., 0., -inf],\n",
      "         [0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.random.manual_seed(0)\n",
    "QKT = torch.rand(5, 5)\n",
    "v = torch.rand(5, 1)\n",
    "attmap = QKT.unsqueeze(0)\n",
    "print(attmap.shape)\n",
    "mask = torch.empty(attmap.shape[0], attmap.shape[1], attmap.shape[2])\n",
    "mask.fill_(float('-inf'))\n",
    "mask.triu_(1)\n",
    "print(mask.shape)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4963,   -inf,   -inf,   -inf,   -inf],\n",
      "         [0.6341, 0.4901,   -inf,   -inf,   -inf],\n",
      "         [0.3489, 0.4017, 0.0223,   -inf,   -inf],\n",
      "         [0.5185, 0.6977, 0.8000, 0.1610,   -inf],\n",
      "         [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]]])\n",
      "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.5359, 0.4641, 0.0000, 0.0000, 0.0000],\n",
      "         [0.3603, 0.3798, 0.2599, 0.0000, 0.0000],\n",
      "         [0.2369, 0.2834, 0.3140, 0.1657, 0.0000],\n",
      "         [0.2001, 0.2528, 0.1506, 0.2426, 0.1540]]])\n"
     ]
    }
   ],
   "source": [
    "masked_attmap = attmap + mask\n",
    "print(masked_attmap)\n",
    "masked_attmap = torch.softmax(masked_attmap, dim=-1)\n",
    "print(masked_attmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 3, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (1): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [nn.Conv2d(3,3,4)] + [nn.Linear(10,10)]*2 \n",
    "nn.Sequential(*temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 64, 64]) torch.Size([2, 4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "h = torch.rand(2, 8, 64, 64)\n",
    "h_mean_part = h[:, :4]\n",
    "h_log_std_part = h[:, 4:]\n",
    "print(h_mean_part.shape, h_log_std_part.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_encoder import Resnet, Pad, Atten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: torch.Size([2, 3, 512, 512])\n",
      "after input_layer: torch.Size([2, 128, 512, 512])\n",
      "after down_1: torch.Size([2, 128, 256, 256])\n",
      "after down_2: torch.Size([2, 256, 128, 128])\n",
      "after down_3: torch.Size([2, 512, 64, 64])\n",
      "after down_4: torch.Size([2, 512, 64, 64])\n",
      "after mid: torch.Size([2, 512, 64, 64])\n",
      "after out_1: torch.Size([2, 8, 64, 64])\n",
      "after out_1: torch.Size([2, 8, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "in_layer = torch.nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1)\n",
    "down_1 = torch.nn.Sequential(\n",
    "    Resnet(128, 128),\n",
    "    Resnet(128, 128),\n",
    "    torch.nn.Sequential(\n",
    "        Pad(),\n",
    "        torch.nn.Conv2d(128, 128, 3, stride=2, padding=0),\n",
    "    ),\n",
    ")\n",
    "down_2 = torch.nn.Sequential(\n",
    "    Resnet(128, 256),\n",
    "    Resnet(256, 256),\n",
    "    torch.nn.Sequential(\n",
    "        Pad(),\n",
    "        torch.nn.Conv2d(256, 256, 3, stride=2, padding=0),\n",
    "    ),\n",
    ")\n",
    "down_3 = torch.nn.Sequential(\n",
    "    Resnet(256, 512),\n",
    "    Resnet(512, 512),\n",
    "    torch.nn.Sequential(\n",
    "        Pad(),\n",
    "        torch.nn.Conv2d(512, 512, 3, stride=2, padding=0),\n",
    "    ),\n",
    ")\n",
    "\n",
    "down_4 = torch.nn.Sequential(\n",
    "                Resnet(512, 512),\n",
    "                Resnet(512, 512),\n",
    "            )\n",
    "mid = torch.nn.Sequential(\n",
    "    Resnet(512, 512),\n",
    "    Atten(),\n",
    "    Resnet(512, 512),\n",
    ")\n",
    "\n",
    "out_1 = torch.nn.Sequential(\n",
    "    torch.nn.GroupNorm(num_channels=512, num_groups=32, eps=1e-6),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Conv2d(512, 8, 3, padding=1),\n",
    ")\n",
    "\n",
    "out_2 = torch.nn.Conv2d(8, 8, 1)\n",
    "\n",
    "input = torch.rand(2, 3, 512, 512)\n",
    "print('input dim:', input.shape)\n",
    "out = in_layer(input)\n",
    "print('after input_layer:', out.shape)\n",
    "out = down_1(out)\n",
    "print('after down_1:', out.shape)\n",
    "out = down_2(out)\n",
    "print('after down_2:', out.shape)\n",
    "out = down_3(out)\n",
    "print('after down_3:', out.shape)\n",
    "out = down_4(out)\n",
    "print('after down_4:', out.shape)\n",
    "out = mid(out)\n",
    "print('after mid:', out.shape)\n",
    "out = out_1(out)\n",
    "print('after out_1:', out.shape)\n",
    "out = out_2(out)\n",
    "print('after out_1:', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal transformation\n",
    "mean = h[:, :4]\n",
    "# [1, 4, 64, 64]\n",
    "logvar = h[:, 4:]\n",
    "std = logvar.exp()**0.5\n",
    "\n",
    "# [1, 4, 64, 64]\n",
    "h = torch.randn(mean.shape, device=mean.device)\n",
    "h = mean + std * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in\n",
    "in_1 = torch.nn.Conv2d(4, 4, 1)\n",
    "\n",
    "\n",
    "in_2 = torch.nn.Conv2d(4, 512, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# middle\n",
    "middle_1 = torch.nn.Sequential(Resnet(512, 512), Atten(), Resnet(512, 512))\n",
    "\n",
    "# up\n",
    "up_1 = torch.nn.Sequential(\n",
    "    Resnet(512, 512),\n",
    "    Resnet(512, 512),\n",
    "    Resnet(512, 512),\n",
    "    torch.nn.Upsample(scale_factor=2.0, mode='nearest'),\n",
    "    torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    ")\n",
    "up_2 = torch.nn.Sequential(\n",
    "    Resnet(512, 512),\n",
    "    Resnet(512, 512),\n",
    "    Resnet(512, 512),\n",
    "    torch.nn.Upsample(scale_factor=2.0, mode='nearest'),\n",
    "    torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    ")\n",
    "up_3 = torch.nn.Sequential(\n",
    "    Resnet(512, 256),\n",
    "    Resnet(256, 256),\n",
    "    Resnet(256, 256),\n",
    "    torch.nn.Upsample(scale_factor=2.0, mode='nearest'),\n",
    "    torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    ")\n",
    "up_4 = torch.nn.Sequential(\n",
    "    Resnet(256, 128),\n",
    "    Resnet(128, 128),\n",
    "    Resnet(128, 128),\n",
    ")\n",
    "\n",
    "\n",
    "out_1 = torch.nn.Sequential(\n",
    "    torch.nn.GroupNorm(num_channels=128, num_groups=32, eps=1e-6),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Conv2d(128, 3, 3, padding=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dim: torch.Size([2, 4, 64, 64])\n",
      "after in_1: torch.Size([2, 4, 64, 64])\n",
      "after in_2: torch.Size([2, 512, 64, 64])\n",
      "after middle_1: torch.Size([2, 512, 64, 64])\n",
      "after up_1: torch.Size([2, 512, 128, 128])\n",
      "after up_2: torch.Size([2, 512, 256, 256])\n",
      "after up_3: torch.Size([2, 256, 512, 512])\n",
      "after up_4: torch.Size([2, 128, 512, 512])\n",
      "after out_1: torch.Size([2, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "input = h\n",
    "print('input dim:', input.shape)\n",
    "out = in_1(input)\n",
    "print('after in_1:', out.shape)\n",
    "out = in_2(out)\n",
    "print('after in_2:', out.shape)\n",
    "out = middle_1(out)\n",
    "print('after middle_1:', out.shape)\n",
    "out = up_1(out)\n",
    "print('after up_1:', out.shape)\n",
    "out = up_2(out)\n",
    "print('after up_2:', out.shape)\n",
    "out = up_3(out)\n",
    "print('after up_3:', out.shape)\n",
    "out = up_4(out)\n",
    "print('after up_4:', out.shape)\n",
    "out = out_1(out)\n",
    "print('after out_1:', out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
