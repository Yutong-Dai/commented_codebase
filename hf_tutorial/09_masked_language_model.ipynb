{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: masked language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. pkgs loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. load data\n",
    "\n",
    "raw dataset can be downloaded from `https://github.com/zyds/transformers-code/tree/master/02-NLP%20Tasks/14-language_model/wiki_cn_filtered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.load_from_disk('data/wiki_cn_filtered/')\n",
    "datasets = ds.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'wikipedia.zh2307',\n",
       " 'completion': \"西安交通大学博物馆（Xi'an Jiaotong University Museum）是一座位于西安交通大学的博物馆，馆长是锺明善。\\n历史\\n2004年9月20日开始筹建，2013年4月8日正式建成开馆，位于西安交通大学兴庆校区陕西省西安市咸宁西路28号。建筑面积6,800平米，展厅面积4,500平米，馆藏文物4,900余件。包括历代艺术文物馆、碑石书法馆、西部农民画馆、邢良坤陶瓷艺术馆、陕西秦腔博物馆和书画展厅共五馆一厅。\\n营业时间\\n* 周一至周六：上午九点至十二点，下午一点至五点\\n* 周日闭馆\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c7477e86ae45c997cfacf6beed2bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/9000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c6173fd8e34573a16771490e6a9c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = 'hfl/chinese-macbert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt)\n",
    "\n",
    "def process_function(examples):\n",
    "    return tokenizer(examples['completion'], truncation=True, max_length=384)\n",
    "\n",
    "tokenized_datasets = datasets.map(process_function, batched=True, num_proc=4, remove_columns=ds.column_names)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dl = DataLoader(tokenized_datasets['train'], batch_size=8, shuffle=False, collate_fn=DataCollatorForLanguageModeling(tokenizer, mlm=True, mlm_probability=0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "batch = next(enumerate(dl))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100, -100, 8024, -100, 1399, -100, -100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'][0][15:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2157,  518,  103, 1333,  103, 8038,  517])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'][0][15:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'家 》 [MASK] 原 [MASK] ： 《'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][0][15:22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-macbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForMaskedLM.from_pretrained(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. config training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(output_dir='./masked_lm', \n",
    "                            per_device_train_batch_size=32,\n",
    "                            per_device_eval_batch_size=64,\n",
    "                            num_train_epochs=1,\n",
    "                            logging_steps=10,\n",
    "                            load_best_model_at_end=True,\n",
    "                            evaluation_strategy='epoch',\n",
    "                            save_strategy='epoch',\n",
    "                            save_total_limit=2,\n",
    "                            report_to='none',\n",
    "                            )\n",
    "trainer = Trainer(model=model, args=args, train_dataset= tokenized_datasets['train'], eval_dataset=tokenized_datasets['test'],\n",
    "        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=True, mlm_probability=0.15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yutong/anaconda3/envs/IMP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [141/141 02:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.298100</td>\n",
       "      <td>1.217772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=141, training_loss=1.3259769179296832, metrics={'train_runtime': 129.9371, 'train_samples_per_second': 69.264, 'train_steps_per_second': 1.085, 'total_flos': 1776437692416000.0, 'train_loss': 1.3259769179296832, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9999794960021973,\n",
       "  'token': 2110,\n",
       "  'token_str': '学',\n",
       "  'sequence': \"西 安 交 通 大 学 博 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆\"},\n",
       " {'score': 1.3157555258658249e-05,\n",
       "  'token': 2119,\n",
       "  'token_str': '學',\n",
       "  'sequence': \"西 安 交 通 大 學 博 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆\"},\n",
       " {'score': 2.415609515082906e-06,\n",
       "  'token': 1920,\n",
       "  'token_str': '大',\n",
       "  'sequence': \"西 安 交 通 大 大 博 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆\"},\n",
       " {'score': 1.4857732821837999e-06,\n",
       "  'token': 7368,\n",
       "  'token_str': '院',\n",
       "  'sequence': \"西 安 交 通 大 院 博 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆\"},\n",
       " {'score': 4.68710368295433e-07,\n",
       "  'token': 6887,\n",
       "  'token_str': '道',\n",
       "  'sequence': \"西 安 交 通 大 道 博 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆\"}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline('fill-mask', model=model, tokenizer=tokenizer, device=0)\n",
    "pipe(\"西安交通大[MASK]博物馆（Xi'an Jiaotong University Museum）是一座位于西安交通大学的博物馆\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe(\"西安交通大[MASK][MASK]物馆（Xi'an Jiaotong University Museum）是一座位于西安交通大学的博物馆\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9998903274536133,\n",
       "  'token': 2110,\n",
       "  'token_str': '学',\n",
       "  'sequence': \"[CLS] 西 安 交 通 大 学 [MASK] 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆 [SEP]\"},\n",
       " {'score': 4.174594869255088e-05,\n",
       "  'token': 2119,\n",
       "  'token_str': '學',\n",
       "  'sequence': \"[CLS] 西 安 交 通 大 學 [MASK] 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆 [SEP]\"},\n",
       " {'score': 4.001786874141544e-05,\n",
       "  'token': 1920,\n",
       "  'token_str': '大',\n",
       "  'sequence': \"[CLS] 西 安 交 通 大 大 [MASK] 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆 [SEP]\"},\n",
       " {'score': 7.771494892949704e-06,\n",
       "  'token': 7368,\n",
       "  'token_str': '院',\n",
       "  'sequence': \"[CLS] 西 安 交 通 大 院 [MASK] 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆 [SEP]\"},\n",
       " {'score': 1.990778855542885e-06,\n",
       "  'token': 1336,\n",
       "  'token_str': '厦',\n",
       "  'sequence': \"[CLS] 西 安 交 通 大 厦 [MASK] 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆 [SEP]\"}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9943378567695618,\n",
       "  'token': 1300,\n",
       "  'token_str': '博',\n",
       "  'sequence': \"[CLS] 西 安 交 通 大 [MASK] 博 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆 [SEP]\"},\n",
       " {'score': 0.003546401159837842,\n",
       "  'token': 1745,\n",
       "  'token_str': '图',\n",
       "  'sequence': \"[CLS] 西 安 交 通 大 [MASK] 图 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆 [SEP]\"},\n",
       " {'score': 0.0011761495843529701,\n",
       "  'token': 3152,\n",
       "  'token_str': '文',\n",
       "  'sequence': \"[CLS] 西 安 交 通 大 [MASK] 文 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆 [SEP]\"},\n",
       " {'score': 0.00017536857922095805,\n",
       "  'token': 5279,\n",
       "  'token_str': '纪',\n",
       "  'sequence': \"[CLS] 西 安 交 通 大 [MASK] 纪 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆 [SEP]\"},\n",
       " {'score': 8.50768992677331e-05,\n",
       "  'token': 1920,\n",
       "  'token_str': '大',\n",
       "  'sequence': \"[CLS] 西 安 交 通 大 [MASK] 大 物 馆 （ xi'an jiaotong university museum ） 是 一 座 位 于 西 安 交 通 大 学 的 博 物 馆 [SEP]\"}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
