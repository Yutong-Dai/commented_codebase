{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: causal language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. pkgs loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. load data\n",
    "\n",
    "raw dataset can be downloaded from `https://github.com/zyds/transformers-code/tree/master/02-NLP%20Tasks/14-language_model/wiki_cn_filtered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.load_from_disk('data/wiki_cn_filtered/')\n",
    "datasets = ds.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'wikipedia.zh2307',\n",
       " 'completion': \"西安交通大学博物馆（Xi'an Jiaotong University Museum）是一座位于西安交通大学的博物馆，馆长是锺明善。\\n历史\\n2004年9月20日开始筹建，2013年4月8日正式建成开馆，位于西安交通大学兴庆校区陕西省西安市咸宁西路28号。建筑面积6,800平米，展厅面积4,500平米，馆藏文物4,900余件。包括历代艺术文物馆、碑石书法馆、西部农民画馆、邢良坤陶瓷艺术馆、陕西秦腔博物馆和书画展厅共五馆一厅。\\n营业时间\\n* 周一至周六：上午九点至十二点，下午一点至五点\\n* 周日闭馆\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 9000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = 'Langboat/bloom-389m-zh'\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt)\n",
    "\n",
    "def process_function(examples):\n",
    "    contents = [e + tokenizer.eos_token for e in examples['completion']]  # Add eos token\n",
    "    return tokenizer(contents, truncation=True, max_length=384)\n",
    "\n",
    "tokenized_datasets = datasets.map(process_function, batched=True, num_proc=4, remove_columns=ds.column_names)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dl = DataLoader(tokenized_datasets['train'], batch_size=8, shuffle=False, collate_fn=DataCollatorForLanguageModeling(tokenizer, mlm=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BloomTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "batch = next(enumerate(dl))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  4829,  1281,   569, 10756,   916,  3128,   109,  3128,\n",
       "          239,  3128,   236,  3128,   240,  3128,   231,  3128,   228,   210,\n",
       "         3128,    98,  3128,   228,  3128,   239,  3128,   232,  3128,   229,\n",
       "         3128,   228,   915,   355, 32753,  1575,  1575,  5908,  4829,  1281,\n",
       "          569, 10756,   916,  3128,   230,  3128,   232,  3128,   244,  3128,\n",
       "          230,  3128,   232,  3128,    99,  3128,   236,  3128,    98,   210,\n",
       "         3128,    98,  3128,   228,  3128,   239,  3128,   232,  3128,   229,\n",
       "         3128,   236,  3128,    98,   210,  3128,   232,  3128,   237,  3128,\n",
       "          238,  3128,   232,  3128,    98,  3128,   236,  3128,   228,   355,\n",
       "          714, 15572, 14395,  1051,    76, 29222,   915,   355,   583,  5317,\n",
       "        18976,  2506,  8536,  5615,  3625, 16410, 18976,  1364, 16080, 10756,\n",
       "          355,  7518,    21, 11909,  2211,   916,    26,  7699, 15429,   355,\n",
       "         5317,  2506,  8536,  1798,  1517, 26281,   671,  4829,  1281,   569,\n",
       "        10756,  1293,  9123,  7892,  7645, 29214,   937,  1425,  6868, 10186,\n",
       "          355, 13066,  5963,  2450, 10756,  1020,  6701,   553,  5888,  5284,\n",
       "          641, 13530, 12363,  9462,   420,   583, 18976,  6701,   373, 19518,\n",
       "         2606,   420, 19788, 12342, 16218,  1693,  3711,  1210,  7231, 29169,\n",
       "          355, 10756,  4415,   775, 20075,  1107,  4128, 17522,  3547, 11134,\n",
       "         2779, 35440,   420,     2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
       "            3,     3,  4829,  1281,   569, 10756,   916,  3128,   109,  3128,\n",
       "          239,  3128,   236,  3128,   240,  3128,   231,  3128,   228,   210,\n",
       "         3128,    98,  3128,   228,  3128,   239,  3128,   232,  3128,   229,\n",
       "         3128,   228,   915,   355, 32753,  1575,  1575,  5908,  4829,  1281,\n",
       "          569, 10756,   916,  3128,   230,  3128,   232,  3128,   244,  3128,\n",
       "          230,  3128,   232,  3128,    99,  3128,   236,  3128,    98,   210,\n",
       "         3128,    98,  3128,   228,  3128,   239,  3128,   232,  3128,   229,\n",
       "         3128,   236,  3128,    98,   210,  3128,   232,  3128,   237,  3128,\n",
       "          238,  3128,   232,  3128,    98,  3128,   236,  3128,   228,   355,\n",
       "          714, 15572, 14395,  1051,    76, 29222,   915,   355,   583,  5317,\n",
       "        18976,  2506,  8536,  5615,  3625, 16410, 18976,  1364, 16080, 10756,\n",
       "          355,  7518,    21, 11909,  2211,   916,    26,  7699, 15429,   355,\n",
       "         5317,  2506,  8536,  1798,  1517, 26281,   671,  4829,  1281,   569,\n",
       "        10756,  1293,  9123,  7892,  7645, 29214,   937,  1425,  6868, 10186,\n",
       "          355, 13066,  5963,  2450, 10756,  1020,  6701,   553,  5888,  5284,\n",
       "          641, 13530, 12363,  9462,   420,   583, 18976,  6701,   373, 19518,\n",
       "         2606,   420, 19788, 12342, 16218,  1693,  3711,  1210,  7231, 29169,\n",
       "          355, 10756,  4415,   775, 20075,  1107,  4128, 17522,  3547, 11134,\n",
       "         2779, 35440,   420,     2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>圣三一教堂（წმინდა სამება），俗称格格蒂圣三一教堂（გერგეტის სამების ეკლესია，以附近的Gergeti而得名），是位于格鲁吉亚卡兹贝吉市的格鲁吉亚正教会教堂，海拔2170米（7120英尺），位于卡兹别克山下。\\n圣三一教堂由一位不知名的建筑师于14世纪建造，整体范围包括教堂主建筑、钟楼和周围的外墙。是格鲁吉亚建筑的典型代表。因其壮阔山景与宗教氛围，教堂目前为信徒及健行者喜爱的朝圣地。</s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0899917c15e7443f8e2036b33bb30962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/801 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b94feca8dba4f5fbc1522214c60a9e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. config training args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(output_dir='./causal_lm', \n",
    "                            per_device_train_batch_size=8,\n",
    "                            gradient_accumulation_steps=4,\n",
    "                            per_device_eval_batch_size=8,\n",
    "                            num_train_epochs=1,\n",
    "                            logging_steps=10,\n",
    "                            load_best_model_at_end=True,\n",
    "                            evaluation_strategy='epoch',\n",
    "                            save_strategy='epoch',\n",
    "                            save_total_limit=1,\n",
    "                            report_to='none',\n",
    "                            )\n",
    "trainer = Trainer(model=model, args=args, train_dataset= tokenized_datasets['train'], eval_dataset=tokenized_datasets['test'],\n",
    "        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"西安交通大学博物馆（Xi'an Jiaotong University Museum）是一座位于西安交通大学的科研、人文图书馆和中国最大的爱国主义展览馆。馆内藏品由古人类化石、古墓群、出土文物，以及近现代出土的中国革命文物。\\n西安交通大学博物馆陈列了来自中国社会各领域的重要\"}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, device=0)\n",
    "pipe(\"西安交通大学博物馆（Xi'an Jiaotong University Museum）是一座位于西安交通大学的\", max_length=64, do_sample=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IMP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
